import os
import logging
import openai
import telegram
import requests
from flask import Flask, request, jsonify, render_template
from telegram.ext import Application, MessageHandler, filters, CommandHandler

# ðŸ”¹ Umgebungsvariablen fÃ¼r API-Keys
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ðŸ”¹ Logging einrichten
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logger = logging.getLogger(__name__)

# ðŸ”¹ Flask-App initialisieren
app = Flask(__name__)

# ðŸ”¹ OpenAI-Client initialisieren
openai.api_key = OPENAI_API_KEY

# ðŸ”¹ Telegram-Bot initialisieren
bot = telegram.Bot(token=TELEGRAM_BOT_TOKEN)
application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

# ðŸ”¹ Funktion zum Generieren von Antworten mit OpenAI GPT-4o
def generate_response(message):
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are an AI assistant for a Telegram bot. Answer concisely and helpfully."},
            {"role": "user", "content": message},
        ],
        max_tokens=150,
    )
    return response.choices[0].message.content.strip()

# ðŸ”¹ /start Befehl
async def start(update, context):
    await update.message.reply_text("Hallo! Ich bin dein AI-Chatbot. Stelle mir eine Frage!")

# ðŸ”¹ /help Befehl
async def help_command(update, context):
    await update.message.reply_text("Sende mir eine Nachricht, und ich werde mit AI antworten!")

# ðŸ”¹ Nachricht-Handler fÃ¼r alle Texteingaben
async def handle_message(update, context):
    message = update.message.text
    response = generate_response(message)
    await context.bot.send_message(chat_id=update.effective_chat.id, text=response)

# ðŸ”¹ Bilder generieren
@app.route('/', methods=['GET', 'POST'])
def index():
    image_url = None

    if request.method == 'POST':
        prompt = request.form['prompt']
        response = openai.Image.create(
            model="dall-e-3",
            prompt=prompt,
            size="1024x1024",
            quality="hd",
            n=1,
        )
        image_url = response['data'][0]['url']

    return render_template('index.html', image_url=image_url)

# ðŸ”¹ Bilderkennung
@app.route('/analyze-image', methods=['POST'])
def analyze_image():
    data = request.json
    image_data = data.get('image_data')
    image_url = data.get('image_url')

    api_url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {OPENAI_API_KEY}"
    }

    messages = [{
        "role": "user",
        "content": [
            {"type": "text", "text": "Hello at plyonrender, below is your analysis..."}
        ]
    }]

    if image_data:
        messages[0]["content"].append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}
        })
    elif image_url:
        messages[0]["content"].append({
            "type": "image_url",
            "image_url": {"url": image_url}
        })

    payload = {
        "model": "gpt-4-vision-preview",
        "messages": messages,
        "max_tokens": 3000
    }

    response = requests.post(api_url, headers=headers, json=payload)
    return jsonify(response.json())

# ðŸ”¹ Fehlerbehandlung
async def error_handler(update, context):
    logger.error(f"Fehler: {context.error}")

# ðŸ”¹ Handler hinzufÃ¼gen
application.add_handler(CommandHandler("start", start))
application.add_handler(CommandHandler("help", help_command))
application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

# ðŸ”¹ Flask und Polling gleichzeitig starten
if __name__ == "__main__":
    from threading import Thread

    Thread(target=lambda: app.run(host='0.0.0.0', port=int(os.environ.get("PORT", 5000)), debug=True)).start()
    application.run_polling()
